{"nbformat":4,"nbformat_minor":0,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"orig_nbformat":2,"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"colab":{"name":"Thesis_NB5.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"KjIszMcCcNZN"},"source":["# Kyle Calabro\n","# DATA 750 - Thesis in Data Science\n","# 16 September 2021\n","---"]},{"cell_type":"markdown","metadata":{"id":"NCRc9P19cNZR"},"source":["# Notebook Five:\n","---\n","## Generate log-mel sepctrogram values for original training data, augmented training data and testing data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mSV-Jm5AcNZS","executionInfo":{"status":"ok","timestamp":1632765169785,"user_tz":240,"elapsed":23568,"user":{"displayName":"Kyle Calabro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJCpfIRYlEdA9zLMKCDRgRfZV9ePscljFy7WxY=s64","userId":"04804643949587696788"}},"outputId":"519825a3-07c7-40f7-909d-b7af3560369a"},"source":["import librosa\n","import librosa.display\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt \n","from matplotlib.pyplot import specgram\n","\n","import seaborn as sns\n","\n","import IPython.display as ipd\n","from IPython.display import Audio\n","\n","import seaborn as sns\n","\n","import numpy as np\n","import pandas as pd\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","import os\n","import sys\n","import warnings\n","\n","import time\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn import preprocessing\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import classification_report, confusion_matrix\n","\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n","from tensorflow.keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization, Dense\n","from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.applications import vgg16\n","\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","\n","# To ignore deprecation warnings...\n","if not sys.warnoptions:\n","    warnings.simplefilter(\"ignore\")\n","warnings.filterwarnings(\"ignore\", category = DeprecationWarning)\n","\n","np.random.seed(42)\n","#tf.random.set_random_seed(42)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"IP5Bp4aocNZX"},"source":["# Utility Functions\n","---"]},{"cell_type":"code","metadata":{"id":"uJkqGY-5cNZX"},"source":["# To generate the log-mel sepctrogram values of a given audio file\n","# Params:\n","    # audio_data: audio time series\n","    # sr: target sampling rate\n","\n","def generate_log_spectrogram(audio_data, sr):\n","    spectrogram = librosa.feature.melspectrogram(y = audio_data, sr = sr, n_mels = 128, fmax = 8000)\n","    spectrogram = librosa.power_to_db(spectrogram)\n","    return spectrogram"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"STV6EAnlcNZc"},"source":["# To save the log-mel sepctrogram image of a given audio file\n","# Params:\n","    # spectrogram: nparray of log-mel spectrogram values\n","    # path: path to save the image file to\n","\n","def save_spectrogram(spectrogram, path):\n","    # Strip the figure of the axes and labels so it represents only the audio content\n","    fig = plt.figure()\n","    ax = fig.add_subplot()\n","    ax.axes.get_xaxis().set_visible(False)\n","    ax.axes.get_yaxis().set_visible(False)\n","    ax.set_frame_on(False)\n","\n","    spec = librosa.display.specshow(spectrogram, fmax = 8000);\n","\n","    plt.savefig(path, bbox_inches = \"tight\", pad_inches = 0)\n","    plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i_DSSGBLcNZc"},"source":["# Data Augmentation Functions\n","---"]},{"cell_type":"code","metadata":{"id":"ZbNq6EYNcNZf"},"source":["# To add random noise to the audio file\n","# Params:\n","    # data: The data to augment (audio time series)\n","    \n","def add_noise(data):\n","    noise = .05 * np.random.uniform() * np.amax(data)\n","    data_noise = data.astype(\"float64\") + noise * np.random.normal(size = data.shape[0])\n","    return data_noise"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kD-roKapcNZg"},"source":["# To shift the audio in a given audio file left or right by a random value\n","# Params:\n","    # data: The data to augment (audio time series)\n","    \n","def shift_audio(data):\n","    return np.roll(data, 1600)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e9Q6xLBOcNZh"},"source":["# To stretch a given audio file by a fixed rate (change the speed)\n","# Params:\n","    # data: The data to augment (audio time series)\n","    # rate: The stretch factor (> 1 = signal sped up, < 1 = signal slowed down)\n","    \n","def stretch_audio(data, rate = .8):\n","    return librosa.effects.time_stretch(data, rate)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"13W5fLZ_cNZk"},"source":["# To shift the pitch of a waveform up by a major third\n","# Params:\n","    # data: The data to augment (audio time series)\n","    # sr: The audio sampling rate of the data\n","    \n","def pitch_majorThird(data, sr):\n","    return librosa.effects.pitch_shift(data, sr, n_steps = 4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wdbHllB1cNZl"},"source":["# To shift the pitch of a waveform down by a tritone\n","# Params:\n","    # data: The data to augment (audio time series)\n","    # sr: The audio sampling rate of the data\n","    \n","def pitch_tritone(data, sr):\n","        return librosa.effects.pitch_shift(data, sr, n_steps = -6)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zFOwWL9mcNZl"},"source":["# To shift the pitch of a waveform by three quarter-tones\n","# Params:\n","    # data: The data to augment (audio time series)\n","    # sr: The audio sampling rate of the data\n","    \n","def pitch_quarter_tone(data, sr):\n","        # Bins_per_octave -> number of steps per octave\n","        return librosa.effects.pitch_shift(data, sr, n_steps = 3, bins_per_octave = 24)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z10_WPg2cNZl"},"source":["# Bringing in the Data\n","----"]},{"cell_type":"code","metadata":{"id":"2iXbgN6XcNaT"},"source":["audio_df = pd.read_csv(\"/content/drive/My Drive/Thesis/audio_df.csv\", usecols = [\"Emotion\", \"path\", \"Gender\", \"Actor\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"amvcoS5YenuP"},"source":["# Convert path to work properly with google drive/colab\n","audio_df.path = audio_df.path.apply(lambda x: \"/content/drive/My Drive/Thesis\" + x[1:])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"NLnRnpZmcNaU","executionInfo":{"status":"ok","timestamp":1632762795808,"user_tz":240,"elapsed":162,"user":{"displayName":"Kyle Calabro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJCpfIRYlEdA9zLMKCDRgRfZV9ePscljFy7WxY=s64","userId":"04804643949587696788"}},"outputId":"613ee996-1320-4ae6-b3cf-882dc5008f92"},"source":["audio_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Gender</th>\n","      <th>Emotion</th>\n","      <th>Actor</th>\n","      <th>path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>male</td>\n","      <td>Surprise</td>\n","      <td>1</td>\n","      <td>/content/drive/My Drive/Thesis/data/audio_file...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>male</td>\n","      <td>Surprise</td>\n","      <td>1</td>\n","      <td>/content/drive/My Drive/Thesis/data/audio_file...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>male</td>\n","      <td>Angry</td>\n","      <td>1</td>\n","      <td>/content/drive/My Drive/Thesis/data/audio_file...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>male</td>\n","      <td>Fear</td>\n","      <td>1</td>\n","      <td>/content/drive/My Drive/Thesis/data/audio_file...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>male</td>\n","      <td>Fear</td>\n","      <td>1</td>\n","      <td>/content/drive/My Drive/Thesis/data/audio_file...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Gender   Emotion  Actor                                               path\n","0   male  Surprise      1  /content/drive/My Drive/Thesis/data/audio_file...\n","1   male  Surprise      1  /content/drive/My Drive/Thesis/data/audio_file...\n","2   male     Angry      1  /content/drive/My Drive/Thesis/data/audio_file...\n","3   male      Fear      1  /content/drive/My Drive/Thesis/data/audio_file...\n","4   male      Fear      1  /content/drive/My Drive/Thesis/data/audio_file..."]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"dSuQWn-8ejil"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nv93y4vpcNaV"},"source":["## Splitting the data into training and test sets, 80% train, 20% test\n","---"]},{"cell_type":"code","metadata":{"id":"K4R-Hd7rcNa8"},"source":["train_data, test_data = train_test_split(audio_df, test_size = .2, random_state = 42, stratify = audio_df[[\"Emotion\", \"Gender\", \"Actor\"]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"mxloIRvvcNa8","executionInfo":{"status":"ok","timestamp":1632765185403,"user_tz":240,"elapsed":100,"user":{"displayName":"Kyle Calabro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJCpfIRYlEdA9zLMKCDRgRfZV9ePscljFy7WxY=s64","userId":"04804643949587696788"}},"outputId":"39c1fb0a-6a36-4e3d-db7e-76dc0b3fed07"},"source":["train_data.reset_index(drop = True, inplace = True)\n","train_data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Gender</th>\n","      <th>Emotion</th>\n","      <th>Actor</th>\n","      <th>path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>male</td>\n","      <td>Disgust</td>\n","      <td>13</td>\n","      <td>/content/drive/My Drive/Thesis/data/audio_file...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>female</td>\n","      <td>Disgust</td>\n","      <td>4</td>\n","      <td>/content/drive/My Drive/Thesis/data/audio_file...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>male</td>\n","      <td>Angry</td>\n","      <td>3</td>\n","      <td>/content/drive/My Drive/Thesis/data/audio_file...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>male</td>\n","      <td>Angry</td>\n","      <td>5</td>\n","      <td>/content/drive/My Drive/Thesis/data/audio_file...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>male</td>\n","      <td>Fear</td>\n","      <td>15</td>\n","      <td>/content/drive/My Drive/Thesis/data/audio_file...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Gender  Emotion  Actor                                               path\n","0    male  Disgust     13  /content/drive/My Drive/Thesis/data/audio_file...\n","1  female  Disgust      4  /content/drive/My Drive/Thesis/data/audio_file...\n","2    male    Angry      3  /content/drive/My Drive/Thesis/data/audio_file...\n","3    male    Angry      5  /content/drive/My Drive/Thesis/data/audio_file...\n","4    male     Fear     15  /content/drive/My Drive/Thesis/data/audio_file..."]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"rGcyQswXcNa9","executionInfo":{"status":"ok","timestamp":1632765186586,"user_tz":240,"elapsed":102,"user":{"displayName":"Kyle Calabro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJCpfIRYlEdA9zLMKCDRgRfZV9ePscljFy7WxY=s64","userId":"04804643949587696788"}},"outputId":"f283bb6d-cb3d-401a-b0de-9ec5f63b7919"},"source":["test_data.reset_index(drop = True, inplace = True)\n","test_data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Gender</th>\n","      <th>Emotion</th>\n","      <th>Actor</th>\n","      <th>path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>female</td>\n","      <td>Disgust</td>\n","      <td>22</td>\n","      <td>/content/drive/My Drive/Thesis/data/audio_file...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>female</td>\n","      <td>Disgust</td>\n","      <td>12</td>\n","      <td>/content/drive/My Drive/Thesis/data/audio_file...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>female</td>\n","      <td>Neutral</td>\n","      <td>20</td>\n","      <td>/content/drive/My Drive/Thesis/data/audio_file...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>male</td>\n","      <td>Happy</td>\n","      <td>13</td>\n","      <td>/content/drive/My Drive/Thesis/data/audio_file...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>female</td>\n","      <td>Sad</td>\n","      <td>12</td>\n","      <td>/content/drive/My Drive/Thesis/data/audio_file...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Gender  Emotion  Actor                                               path\n","0  female  Disgust     22  /content/drive/My Drive/Thesis/data/audio_file...\n","1  female  Disgust     12  /content/drive/My Drive/Thesis/data/audio_file...\n","2  female  Neutral     20  /content/drive/My Drive/Thesis/data/audio_file...\n","3    male    Happy     13  /content/drive/My Drive/Thesis/data/audio_file...\n","4  female      Sad     12  /content/drive/My Drive/Thesis/data/audio_file..."]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"qCNEHUMScNa9"},"source":["# Feature Extraction\n","---\n","### Iterating over all the audio files, generate the values for the log-mel spectrograms"]},{"cell_type":"markdown","metadata":{"id":"JcnezyPicNa9"},"source":["## Training Data\n","---"]},{"cell_type":"code","metadata":{"id":"5rjOce26cNa9"},"source":["train_df = pd.DataFrame(columns = [\"mel_spectrogram\"])\n","\n","counter = 0\n","\n","for index, path in enumerate(train_data.path):\n","    data, sr = librosa.load(path, res_type = \"kaiser_fast\", duration = 3, sr = 44100, offset = .5)\n","\n","    # Retrieve the mel-scaled spectrograms for all augmentations, transforming both the y-axis (frequency) to log scale,\n","    # and the x-axis (color/amplitude) to Decibels, i.e. log scale of amplitudes\n","\n","    # Get the spectrogram of the original, unaugmented data\n","    orig_spectrogram = generate_log_spectrogram(data, sr)\n","    train_df.loc[counter] = [orig_spectrogram]\n","\n","    counter = counter + 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hQzmsTs_cNa-"},"source":["train_df = pd.concat([train_data.drop(columns = \"path\"), pd.DataFrame(train_df[\"mel_spectrogram\"])], axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B_9HX4dPcNa-","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"928b6645-b9cc-4f27-c2de-7b99ffd188b2"},"source":["train_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Gender</th>\n","      <th>Emotion</th>\n","      <th>Actor</th>\n","      <th>mel_spectrogram</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>male</td>\n","      <td>Disgust</td>\n","      <td>13</td>\n","      <td>[[-42.014637, -41.229786, -43.67878, -45.01442...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>female</td>\n","      <td>Disgust</td>\n","      <td>4</td>\n","      <td>[[-68.426315, -68.426315, -68.426315, -68.4263...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>male</td>\n","      <td>Angry</td>\n","      <td>3</td>\n","      <td>[[-67.182045, -67.14102, -64.01513, -66.515755...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>male</td>\n","      <td>Angry</td>\n","      <td>5</td>\n","      <td>[[-54.92186, -55.697502, -57.20272, -52.536354...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>male</td>\n","      <td>Fear</td>\n","      <td>15</td>\n","      <td>[[-41.92892, -44.034023, -47.75731, -43.322655...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Gender  Emotion  Actor                                    mel_spectrogram\n","0    male  Disgust     13  [[-42.014637, -41.229786, -43.67878, -45.01442...\n","1  female  Disgust      4  [[-68.426315, -68.426315, -68.426315, -68.4263...\n","2    male    Angry      3  [[-67.182045, -67.14102, -64.01513, -66.515755...\n","3    male    Angry      5  [[-54.92186, -55.697502, -57.20272, -52.536354...\n","4    male     Fear     15  [[-41.92892, -44.034023, -47.75731, -43.322655..."]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"64VBZTG8cNa-"},"source":["## Testing Data\n","---"]},{"cell_type":"code","metadata":{"id":"5J5rRayTcNa-"},"source":["test_df = pd.DataFrame(columns = [\"mel_spectrogram\"])\n","\n","counter = 0\n","\n","# Retrieve the mel-scaled spectrograms for all testing data, transforming both the y-axis (frequency) to log scale,\n","# and the x-axis (color/amplitude) to Decibels, i.e. log scale of amplitudes\n","for index, path in enumerate(test_data.path):\n","    data, sr = librosa.load(path, res_type = \"kaiser_fast\", duration = 3, sr = 44100, offset = .5)\n","\n","    # Get the spectrogram of the original, unaugmented data\n","    orig_spectrogram = generate_log_spectrogram(data, sr)\n","    test_df.loc[counter] = [orig_spectrogram]\n","\n","    counter = counter + 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DEHfMB1PcNa_"},"source":["test_df = pd.concat([test_data.drop(columns = \"path\"), pd.DataFrame(test_df[\"mel_spectrogram\"])], axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ga5mNj0tcNa_","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"01651af6-db15-45da-9b84-549bcc5c336a"},"source":["test_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Gender</th>\n","      <th>Emotion</th>\n","      <th>Actor</th>\n","      <th>mel_spectrogram</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>female</td>\n","      <td>Disgust</td>\n","      <td>22</td>\n","      <td>[[-50.69049, -54.978943, -64.96961, -63.848305...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>female</td>\n","      <td>Disgust</td>\n","      <td>12</td>\n","      <td>[[-52.43086, -49.4553, -53.096275, -59.1045, -...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>female</td>\n","      <td>Neutral</td>\n","      <td>20</td>\n","      <td>[[-78.72657, -78.72657, -78.72657, -78.72657, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>male</td>\n","      <td>Happy</td>\n","      <td>13</td>\n","      <td>[[-52.144207, -46.53559, -44.30996, -48.127254...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>female</td>\n","      <td>Sad</td>\n","      <td>12</td>\n","      <td>[[-59.734955, -59.734955, -59.734955, -59.7349...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Gender  Emotion  Actor                                    mel_spectrogram\n","0  female  Disgust     22  [[-50.69049, -54.978943, -64.96961, -63.848305...\n","1  female  Disgust     12  [[-52.43086, -49.4553, -53.096275, -59.1045, -...\n","2  female  Neutral     20  [[-78.72657, -78.72657, -78.72657, -78.72657, ...\n","3    male    Happy     13  [[-52.144207, -46.53559, -44.30996, -48.127254...\n","4  female      Sad     12  [[-59.734955, -59.734955, -59.734955, -59.7349..."]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"Saf2PtyJcNa_"},"source":["---"]},{"cell_type":"code","metadata":{"id":"Bu_D0ERkcNa_"},"source":["train_df.to_csv(\"/content/drive/My Drive/Thesis/Orig_Train/orig_train_data.csv\")\n","test_df.to_csv(\"/content/drive/My Drive/Thesis/Orig_Test/orig_test_data.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_TgXGwFUcNa_"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"FT-MkdUtcNa_"},"source":["# Feature Extraction for Data Augmentation\n","---\n","### Iterating over all the training data files, generate the values for the log-mel spectrograms for the various augmentations"]},{"cell_type":"code","metadata":{"id":"FK4dSlhQcNa_"},"source":["# Dataframes to hold augmented data\n","\n","noise_df = pd.DataFrame(columns = [\"mel_spectrogram\"])\n","shift_df = pd.DataFrame(columns = [\"mel_spectrogram\"])\n","stretch_half_df = pd.DataFrame(columns = [\"mel_spectrogram\"])\n","stretch_double_df = pd.DataFrame(columns = [\"mel_spectrogram\"])\n","pitch_majorThird_df = pd.DataFrame(columns = [\"mel_spectrogram\"])\n","pitch_tritone_df = pd.DataFrame(columns = [\"mel_spectrogram\"])\n","pitch_quarter_tone_df = pd.DataFrame(columns = [\"mel_spectrogram\"])\n","aug_train_df = pd.DataFrame(columns = [\"mel_spectrogram\"])\n","\n","counter = 0\n","\n","for index, path in enumerate(train_data.path):\n","    data, sr = librosa.load(path, res_type = \"kaiser_fast\", duration = 3, sr = 44100, offset = .5)\n","\n","    # Retrieve the mel-scaled spectrograms for all augmentations, transforming both the y-axis (frequency) to log scale,\n","    # and the x-axis (color/amplitude) to Decibels, i.e. log scale of amplitudes\n","    noise_augmentation = add_noise(data)\n","    shift_augmentation = shift_audio(data)\n","    stretch_augmentation_half = stretch_audio(data, .8)\n","    stretch_augmentation_double = stretch_audio(data, 1.2)\n","    pitch_majorThird_augmentation = pitch_majorThird(data, sr)\n","    pitch_tritone_augmentation = pitch_tritone(data, sr)\n","    pitch_quarter_tone_augmentation = pitch_quarter_tone(data, sr)\n","\n","    # Get the spectrogram of the data augmented with noise\n","    noise_spectrogram = generate_log_spectrogram(noise_augmentation, sr)\n","    noise_df.loc[counter] = [noise_spectrogram]\n","\n","    # Get the spectrogram of the data augmented via shift\n","    shift_spectrogram = generate_log_spectrogram(shift_augmentation, sr)\n","    shift_df.loc[counter] = [shift_spectrogram]\n","\n","    # Get the spectrogram of the data augmented via stretch by .8\n","    stretch_half_spectrogram = generate_log_spectrogram(stretch_augmentation_half, sr)\n","    stretch_half_df.loc[counter] = [stretch_half_spectrogram]\n","\n","    # Get the spectrogram of the data augmented via stretch by factor of 1.2\n","    stretch_double_spectrogram = generate_log_spectrogram(stretch_augmentation_double, sr)\n","    stretch_double_df.loc[counter] = [stretch_double_spectrogram]\n","\n","    # Get the spectrogram of the data augmented with pitch (Major Third)\n","    majorThird_spectrogram = generate_log_spectrogram(pitch_majorThird_augmentation, sr)\n","    pitch_majorThird_df.loc[counter] = [majorThird_spectrogram]\n","\n","    # Get the spectrogram of the data augmented with pitch (Tri-tone)\n","    tritone_spectrogram = generate_log_spectrogram(pitch_tritone_augmentation, sr)\n","    pitch_tritone_df.loc[counter] = [tritone_spectrogram]\n","\n","    # Get the spectrogram of the data augmented with pitch (Quarter Tone)\n","    quartertone_spectrogram = generate_log_spectrogram(pitch_quarter_tone_augmentation, sr)\n","    pitch_quarter_tone_df.loc[counter] = [quartertone_spectrogram]\n","\n","    # Get the spectrogram of the original, unaugmented data\n","    orig_spectrogram = generate_log_spectrogram(data, sr)\n","    aug_train_df.loc[counter] = [orig_spectrogram]\n","\n","    counter = counter + 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qPug7VBfcNbA"},"source":["# Label the augmentation to make selecting certain augmentations a breeze later\n","noise_df[\"Augmentation\"] = \"Noise\"\n","shift_df[\"Augmentation\"] = \"Shift\"\n","stretch_half_df[\"Augmentation\"] = \"Stretch .8\"\n","stretch_double_df[\"Augmentation\"] = \"Stretch 1.2\"\n","pitch_majorThird_df[\"Augmentation\"] = \"Pitch Major Third\"\n","pitch_tritone_df[\"Augmentation\"] = \"Pitch Tritone\"\n","pitch_quarter_tone_df[\"Augmentation\"] = \"Pitch Quarter tone\"\n","aug_train_df[\"Augmentation\"] = \"None\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t6HWvWuWcNbA"},"source":["# Build out the master dataframe of augmented data, bringing back in the metadata of the audio file as well\n","aug_df = pd.DataFrame(columns = [\"Augmentation\"])\n","\n","aug_df = pd.concat([noise_df.Augmentation, train_data, pd.DataFrame(noise_df[\"mel_spectrogram\"])], axis = 1)\n","\n","aug_df = aug_df.append(pd.concat([shift_df.Augmentation, train_data, pd.DataFrame(shift_df[\"mel_spectrogram\"])], axis = 1))\n","aug_df = aug_df.append(pd.concat([pitch_majorThird_df.Augmentation, train_data, pd.DataFrame(pitch_majorThird_df[\"mel_spectrogram\"])], axis = 1))\n","aug_df = aug_df.append(pd.concat([pitch_tritone_df.Augmentation, train_data, pd.DataFrame(pitch_tritone_df[\"mel_spectrogram\"])], axis = 1))\n","aug_df = aug_df.append(pd.concat([pitch_quarter_tone_df.Augmentation, train_data, pd.DataFrame(pitch_quarter_tone_df[\"mel_spectrogram\"])], axis = 1))\n","aug_df = aug_df.append(pd.concat([stretch_half_df.Augmentation, train_data, pd.DataFrame(stretch_half_df[\"mel_spectrogram\"])], axis = 1))\n","aug_df = aug_df.append(pd.concat([stretch_double_df.Augmentation, train_data, pd.DataFrame(stretch_double_df[\"mel_spectrogram\"])], axis = 1))\n","aug_df = aug_df.append(pd.concat([aug_train_df.Augmentation, train_data, pd.DataFrame(aug_train_df[\"mel_spectrogram\"])], axis = 1))\n","\n","aug_df.drop(columns = \"path\", inplace = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"RvielS0lcNbA","executionInfo":{"status":"ok","timestamp":1632764275427,"user_tz":240,"elapsed":1376,"user":{"displayName":"Kyle Calabro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJCpfIRYlEdA9zLMKCDRgRfZV9ePscljFy7WxY=s64","userId":"04804643949587696788"}},"outputId":"a52410ed-b981-4fed-cf04-b9a67253e369"},"source":["aug_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Augmentation</th>\n","      <th>Gender</th>\n","      <th>Emotion</th>\n","      <th>Actor</th>\n","      <th>mel_spectrogram</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Noise</td>\n","      <td>male</td>\n","      <td>Disgust</td>\n","      <td>13</td>\n","      <td>[[-55.6770425595965, -42.43659733561067, -42.8...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Noise</td>\n","      <td>female</td>\n","      <td>Disgust</td>\n","      <td>4</td>\n","      <td>[[-41.64856659323732, -39.50736436345467, -37....</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Noise</td>\n","      <td>male</td>\n","      <td>Angry</td>\n","      <td>3</td>\n","      <td>[[-34.20474933265983, -37.84025022266927, -38....</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Noise</td>\n","      <td>male</td>\n","      <td>Angry</td>\n","      <td>5</td>\n","      <td>[[-52.49080599303481, -49.924579023838014, -44...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Noise</td>\n","      <td>male</td>\n","      <td>Fear</td>\n","      <td>15</td>\n","      <td>[[-38.079510217392055, -31.096275481650686, -3...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Augmentation  ...                                    mel_spectrogram\n","0        Noise  ...  [[-55.6770425595965, -42.43659733561067, -42.8...\n","1        Noise  ...  [[-41.64856659323732, -39.50736436345467, -37....\n","2        Noise  ...  [[-34.20474933265983, -37.84025022266927, -38....\n","3        Noise  ...  [[-52.49080599303481, -49.924579023838014, -44...\n","4        Noise  ...  [[-38.079510217392055, -31.096275481650686, -3...\n","\n","[5 rows x 5 columns]"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-mJfnvmhcNbB","executionInfo":{"status":"ok","timestamp":1632764279228,"user_tz":240,"elapsed":108,"user":{"displayName":"Kyle Calabro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJCpfIRYlEdA9zLMKCDRgRfZV9ePscljFy7WxY=s64","userId":"04804643949587696788"}},"outputId":"a524713d-e07e-47b8-8028-f603b1c91c7b"},"source":["aug_df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(9216, 5)"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"8AIoj71xcNbB"},"source":["aug_df.to_csv(\"/content/drive/My Drive/Thesis/Aug_Train/aug_train.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oieRxdE1cNbB"},"source":["# Convert Testing Data to Images\n","----"]},{"cell_type":"code","metadata":{"id":"JQ5bd8JacNbB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"717018c2-032c-42a0-8b9b-d8c590ff6789"},"source":["test_df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(288, 4)"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"XpENS7iycNbB"},"source":["# Saving Testing Data Locally\n","for index, mel_spectrogram in enumerate(test_df.mel_spectrogram):\n","    img_path = \"/content/drive/My Drive/Thesis/Orig_Test/{0}.jpeg\".format(index)\n","\n","    save_spectrogram(mel_spectrogram, img_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wMf6ri3pcNbC"},"source":["# Convert Original Training Data to Images\n","----"]},{"cell_type":"code","metadata":{"id":"5grYFo9ycNbC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"445831ad-af70-4182-c430-a2d3b54efd82"},"source":["train_df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1152, 4)"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"rU6voeiKcNbC"},"source":["# Saving Original Training Data Locally\n","for index, mel_spectrogram in enumerate(train_df.mel_spectrogram):\n","    img_path = \"/content/drive/My Drive/Thesis/Orig_Train/{0}.jpeg\".format(index)\n","\n","    save_spectrogram(mel_spectrogram, img_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rLHKoa9ZcNbC"},"source":["# Convert Augmented Training Data to Images\n","----"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"74TrbeoncNbD","outputId":"a046426b-8b91-443c-eab0-9d967ea3e208"},"source":["aug_df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(9216, 5)"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"umq-NKKwcNbD"},"source":["# Saving Augmented Training Data Locally\n","for index, mel_spectrogram in enumerate(aug_df.mel_spectrogram):\n","    img_path = \"/content/drive/My Drive/Thesis/Aug_Train/{0}.jpeg\".format(index)\n","\n","    save_spectrogram(mel_spectrogram, img_path)"],"execution_count":null,"outputs":[]}]}